{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29f2aba8",
   "metadata": {},
   "source": [
    "# Training a BurstCCN on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be475bc0",
   "metadata": {},
   "source": [
    "Import the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a63d78a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SigmoidFA' from 'modules.layers' (C:\\Users\\xn20465\\PycharmProjects\\bio-DL workshop\\modules\\layers.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20800/2312493121.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetworks_burstccn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBurstCCN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimisers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSGDOptimiser\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_mnist_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\PycharmProjects\\bio-DL workshop\\datasets.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetworks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mANN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\bio-DL workshop\\modules\\networks.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSigmoidFA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNodePerturbationOutputLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNodePerturbationHiddenLayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mNodePerturbationConv2dHiddenLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'SigmoidFA' from 'modules.layers' (C:\\Users\\xn20465\\PycharmProjects\\bio-DL workshop\\modules\\layers.py)"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from modules.networks_burstccn import BurstCCN\n",
    "from modules.optimisers import SGDOptimiser\n",
    "from datasets import get_mnist_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de30539",
   "metadata": {},
   "source": [
    "### Model Schematic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2ed0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"img/burstcnn_schematic.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e075766",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c138c13",
   "metadata": {},
   "source": [
    "Setting up model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6d37c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_baseline = 0.5 # Baseline burst probability\n",
    "n_hidden_layers = 3\n",
    "n_hidden_units = 500 # Number of units in each hidden layer\n",
    "\n",
    "Y_learning = False # Whether to learn the feedback Y weights (default=False corresponding to feedback alignment where they are fixed)\n",
    "\n",
    "# Y_mode controls how the Y_weights are initialised\n",
    "# options are 'tied', 'symmetric_init', random_init'\n",
    "# 'random_init': corresponds to the random feedback weights of feedback alignment (default)\n",
    "# 'tied': feedback Y weights are kept symmetric with the feedforward weights throughout training\n",
    "# 'symmetric_init': feedback Y weights are initialised symmetric with feedforward weights but deviate throughout training\n",
    "Y_mode = 'random_init'\n",
    "\n",
    "# Y_scale controls the strength of the Y weights and it's interpretation depends on the Y_mode:\n",
    "# Y_mode='random_init': the scale is the standard deviation of the normal distribution (mean=0) used for initialisation\n",
    "# Y_mode='symmetric_init' or 'tied': is a controls the ratio of feedforward to feedback weights (Y_scale=1 for exact symmetry)\n",
    "Y_scale = 0.5\n",
    "\n",
    "Q_learning = True # Whether to learn the feedback Q weights (default=True such that the Q weights learn to cancel the Y weights)\n",
    "\n",
    "# Similar to Y_mode, Q_mode controls how the Q weights are initialised\n",
    "# Options are the same as before: 'tied', 'symmetric_init', random_init'\n",
    "# 'random_init': corresponds to initially random Q weights that need to align with Y from scratch \n",
    "# 'tied': feedback Q weights are kept symmetric with the feedback Y weights (with a -p_baseline constant ratio i.e. Q = -p_baselineY) such that the two pathways cancel in the absense of an error signal\n",
    "# 'symmetric_init': Q weights are initialised symmetric with the feedback Y weights (as for the 'tied' case) but deviate through training (default)\n",
    "Q_mode = 'symmetric_init'\n",
    "\n",
    "# Q_scale controls the strength of the Q weights and it's interpretation depends on the Q_mode:\n",
    "# Q_mode='random_init': the scale is the standard deviation of the normal distribution (mean=0) used for initialisation\n",
    "# Q_mode='symmetric_init' or 'tied': is a controls the ratio oY to Q weights (recommended value of Q_scale=1.0 in this case)\n",
    "Q_scale = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0d753b",
   "metadata": {},
   "source": [
    "Setting up training parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7bdb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory = os.getcwd()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "n_epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "lr = 0.3\n",
    "lr_Y = 0.0\n",
    "lr_Q = 0.000731\n",
    "\n",
    "momentum = 0.0\n",
    "weight_decay = 0.0\n",
    "\n",
    "\n",
    "data_dir = os.path.join(working_directory, './Data')\n",
    "\n",
    "train_data_loader, _, test_data_loader = get_mnist_dataset(data_dir, train_batch_size=batch_size, use_validation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f79b2b",
   "metadata": {},
   "source": [
    "Create the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae6e2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BurstCCN(n_inputs=784, n_outputs=10, p_baseline=p_baseline,\n",
    "                              n_hidden_layers=n_hidden_layers,\n",
    "                              n_hidden_units=n_hidden_units,\n",
    "                              Y_learning=Y_learning,\n",
    "                              Y_mode=Y_mode,\n",
    "                              Y_scale=Y_scale,\n",
    "                              Q_learning=Q_learning,\n",
    "                              Q_mode=Q_mode,\n",
    "                              Q_scale=Q_scale,\n",
    "                              use_layer_norm=False)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "weight_update_parameters = [layer.weight_grad for layer in model.classification_layers]\n",
    "bias_update_parameters = [layer.bias_grad for layer in model.classification_layers]\n",
    "\n",
    "optimiser = SGDOptimiser(weight_parameters=[layer.weight for layer in model.classification_layers],\n",
    "                        bias_parameters=[layer.bias for layer in model.classification_layers],\n",
    "                        weight_update_parameters=weight_update_parameters,\n",
    "                        bias_update_parameters=bias_update_parameters,\n",
    "                        lr=lr,\n",
    "                        momentum=momentum,\n",
    "                        weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776630c4",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f879d937",
   "metadata": {},
   "source": [
    "Define the training and testing functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ec056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_loader):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    progress_bar = tqdm(data_loader)\n",
    "    for batch_index, (inputs, targets) in enumerate(progress_bar):\n",
    "        optimiser.zero_grad()\n",
    "        inputs, targets = inputs.to(model.device), targets.to(model.device)\n",
    "        t = F.one_hot(targets, num_classes=10).float()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = model.loss(outputs, t)        \n",
    "        \n",
    "        model.backward(t)\n",
    "        \n",
    "        optimiser.step()\n",
    "        \n",
    "        train_loss += loss\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        progress_bar.set_description(\"Train Loss: {:.3f} | Acc: {:.3f}% ({:d}/{:d})\".format(train_loss / (batch_index + 1), 100 * correct / total, correct, total))\n",
    "\n",
    "    return 100.0 * (1.0 - correct / total), train_loss / (batch_index + 1)\n",
    "    \n",
    "def test(data_loader):\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(data_loader)\n",
    "        for batch_idx, (inputs, targets) in enumerate(progress_bar):\n",
    "            inputs, targets = inputs.to(model.device), targets.to(model.device)\n",
    "\n",
    "            t = F.one_hot(targets, num_classes=10).float()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = model.loss(outputs, t)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            progress_bar.set_description(\"Test Loss: {:.3f} | Acc: {:.3f}% ({:d}/{:d})\".format(test_loss / (batch_idx + 1), 100 * correct / total, correct, total))\n",
    "\n",
    "    return 100 * (1.0 - correct / total), test_loss / (batch_idx + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f840a73",
   "metadata": {},
   "source": [
    "Run the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d888e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(f\"\\nEpoch {epoch}.\")\n",
    "    train_error, train_loss = train(train_data_loader)\n",
    "    test_error, test_loss = test(test_data_loader)\n",
    "    \n",
    "    print(f\"Train: {train_error}, Test: {test_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a6cfff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
