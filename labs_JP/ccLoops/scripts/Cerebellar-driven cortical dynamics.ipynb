{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64120e0a",
   "metadata": {},
   "source": [
    "# Cerebellar-driven cortical dynamics\n",
    "Welcome to the \"cerebellar-driven cortical dynamics\" notebook! This notebook provides background into my own (Joe Pemberton's) research on the cortico-cerebellar loop. In particular, I have spent some time developing an artifical neural network based model of cortico-cerebellar interaction in the brain during task acquistion. Using the model, we can show that cerebellar plasticity alone is often enough to drive efficient task dynamics. We can also use the model to replicate *in silico* some exciting recent experimental results. For more context for this notebook, see [this preprint paper](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=B9nk9MQAAAAJ&citation_for_view=B9nk9MQAAAAJ:eQOLeE2rZwMC).\n",
    "\n",
    "In this notebook, first we will go through the background of the model and its implementation. Next we will apply the model to a 'motor-switching' paradigm as in Figure 3 as in [here](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=B9nk9MQAAAAJ&citation_for_view=B9nk9MQAAAAJ:eQOLeE2rZwMC). Finally, I will provide suggestions this work could be extended (but for which I didn't have time to do myself!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d3f0db",
   "metadata": {},
   "source": [
    "## Background: model architecture and plasticity rules\n",
    "<img src=\"https://user-images.githubusercontent.com/35163856/202711207-297cb6db-2a4f-4b1f-989f-f76600c2d1ee.png\" width=\"900\">\n",
    "\n",
    "In this study we will model the temporal dynamics of the brain and how it can solve time-dependent tasks. We separate the model into two distinct components: a **cortical** component - which models some region of the neocortex -- and a **cerebellar** component -- which models some region of the cerebellum. \n",
    "\n",
    "### (Cortical only) no feedback model\n",
    "\n",
    "Cortical circuits, particularly in higher brain areas responsible for solving tasks, are highly recurrent. For this reason we model the cortical network as a recurrent neural network (RNN), where the RNN state $h_t$ represents the 'hidden' cortical state at time $t$. The RNN takes external input $x_t$, and the final cortical output $z_t$ is a linear readout of the hidden state. Let $W_{ih}$, $W_{hh}$ and $W_\\mathrm{rdt}$ denote the input, recurrent and readout weights (synapses) of the cortical network respectively. Then the dynamics of the network can be formally described with\n",
    "\n",
    "$h_t = \\alpha h_{t-1} + W_{hh}f(h_{t-1}) + W_{ih} x_t$ \n",
    "\n",
    "$ z_t = W_{\\mathrm{rdt}}f(h_t)$\n",
    "\n",
    "Where $\\alpha$ denotes the leak of the RNN which is dependent on the membrane time constant of the cortical neurons, and $f$ is the activation function of the RNN which we take as $f(x) = \\tanh(x)$.\n",
    "\n",
    "The above equations are the standard implementation of a leaky RNN and reflect the 'no feedback' architecture in the above figure. \n",
    "\n",
    "### (Cortical only) readout feedback model\n",
    "\n",
    "In this lab we will examine the role that feedback can play onto an RNN. The most obvious way to incorporate feedback is to send the cortical output $z_t$ back into the RNN. This architecture is represented in the 'readout feedback' model in the above figure, and is used in various works in the 2000s including in [echo-state networks](https://www.science.org/doi/10.1126/science.1091277) and the [FORCE](https://pubmed.ncbi.nlm.nih.gov/19709635/) algorithm. Letting $W_{\\mathrm{out},h}$ denote the feedback weights from the cortical output to the RNN, the hidden cortical state now evolves according to\n",
    "\n",
    "$h_t = \\alpha h_{t-1} + W_{hh}f(h_{t-1}) + W_{ih} x_t + W_{\\mathrm{out}-h} z_{t-1}$ \n",
    "\n",
    "This is an important control architecture to consider whilst examining the role of cerebellar feedback. \n",
    "\n",
    "### Cerebellar feedback model\n",
    "\n",
    "The novel architecture that we will examine! In this scheme we attach a cerebellar network to the cortical network; the cerebellar network receives a copy of cortical activity, and sends back a cerebellar prediction. This architecture resembles the cortico-cerebellar loop and is the 'cerebellar feedback' model in the above figure. Letting $\\mathcal{C}$ denote the cerebellar computation and $W_{\\mathcal{C}h}$ the cerebellar-cortico weights, the temporal dynamics then run according to \n",
    "\n",
    "$h_t = \\alpha h_{t-1} + W_{hh}f(h_{t-1}) + W_{ih} x_t + W_{\\mathcal{C}h} c_{t}$ \n",
    "\n",
    "$c_{t} = \\mathcal{C}(f(h_{t-1}))$\n",
    "\n",
    "What is the cerebellar computation $\\mathcal{C}$? We approximate cerebellar processing with two main stages of forward processing. The first stage is the projection from the cortex onto the granular layer of the cerebellum via the mossy fibres; the second stage is the projection from the granule cells onto the Purkinje cells via the parallel fibres. Together, these stages can be approximated by a feedforward network of one hidden layer, where the hidden and output units of the network resemble granule and Purkinje cells, respectively. In particular, the cerebellar computation is\n",
    "\n",
    "$c_{t} = \\mathcal{C}(f(h_{t-1})) = W_{\\mathrm{PF}}f^{\\mathcal{C}}\\left(W_{\\mathrm{MF}}f(h_{t-1})\\right)$\n",
    "\n",
    "where $W_{\\mathrm{MF}}$, $W_{\\mathrm{PF}}$ denote the mossy fibre, parallel fibre weights respectively, and $f^{\\mathcal{C}}$ denotes the cerebellar non-linearity which we set as $f^{\\mathcal{C}}(x) = \\mathrm{ReLU}(x)$. Like the real cerebellum, we generally consider a high number of granule cells, e.g. a 1:20 divergence from the cortical neurons to the cerebellar granular layer. \n",
    "\n",
    "### Cortical plasticity rules\n",
    "\n",
    "As stated earlier, we're interested in how the brain can learn time-dependent tasks. Here we're going to be considering the supervised learning paradigm in which some external 'teacher' provides the desired output to the model. Let $y_t$ denote the desired output at time $t$. The goal of the model then is to minimise the error between the cortical output and desired output, $E_t = \\mathcal{E}(y_t, z_t)$, where $\\mathcal{E}$ is the task error function (e.g. mean-squared error for regression tasks, cross entropy loss for classification tasks). \n",
    "\n",
    "Let $E = \\sum_t E_t$ denote the task error across the entire task sequence. To minimise $E$, we will update our cortical parameters by gradient descent. That is, for a given cortical weight $W$\n",
    "\n",
    "$\\Delta W = - \\eta \\frac{\\partial E}{\\partial W}$\n",
    "\n",
    "Where $\\eta$ is the learning rate. Though $\\frac{\\partial E}{\\partial W}$ is relatively simply to compute for the cortical readout weight $W = W_{\\mathrm{rdt}}$ (one-step backprop in space), solving this gradient for the parameters in the RNN can be challenging. In particular, determining the true gradient normally uses the backpropagation through time (BPTT) algorithm, the computational and memory requirements of which are generally considered [biologically implausible](https://www.sciencedirect.com/science/article/pii/S0959438818302009) in the brain. For this reason, when assumed plastic, we instead use forward-propagating, biologically plausible eligibility traces as in the [eprop algorithm](https://www.nature.com/articles/s41467-020-17236-y). However, as we will see, cerebellar feedback can alleviate the need for plasticity in the cortical RNN at all. \n",
    "\n",
    "### Cerebellar plasticity rules\n",
    "\n",
    "How does the cerebellar network learns? The parallel fibre weights $W_{\\mathrm{PF}}$ are updated so that the cerebellum predicts *future* task targets. Specifically, the cerebellar error is $E^\\mathcal{C}_t = \\mathcal{E}(y_t, c_{t-\\tau})$ for some cerebellar time window $\\tau$. This appeals to the observed timed plasticity rules at the parallel fibre synapse, for which $\\tau$ effectively varies in the hundreds of milliseconds. Moreover, the predictive element of cerebellar output appeals to the notion of the cerebellum as an [internal model](https://www.sciencedirect.com/science/article/pii/S1364661398012212) (specifically forward model) of the nervous system. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51b8e2f",
   "metadata": {},
   "source": [
    "## Required libraries and functions\n",
    "Let's load the required python libraries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee8611ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import ignite\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sacred\n",
    "from sacred import Experiment\n",
    "from ignite.engine import Events\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"ignite\").setLevel(logging.WARNING) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d975cd4b",
   "metadata": {},
   "source": [
    "... and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d834c5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load experiment ingredients\n",
    "from ingredients.dataset import linedraw as dataset, load_linedraw as load_dataset\n",
    "    \n",
    "from ingredients.model import model, init_model\n",
    "from ingredients.training import training, init_metrics, init_optimizer, \\\n",
    "                                 create_rnn_trainer, create_rnn_evaluator, \\\n",
    "                                 Tracer, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a7354e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training.add_config('multitask/configs/training.yaml')\n",
    "model.add_config('multitask/configs/model.yaml')\n",
    "dataset.add_config('multitask/configs/dataset.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6348a172",
   "metadata": {},
   "source": [
    "## Pre-experiment booking\n",
    "Inspired by the vast number of granule cells in the cerebellum (they constitute $>50\\%$ of the brain's neurons alone!), we apply a significant cortico-cerebellar expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b91cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OBSERVE = False #save model results\n",
    "temp_path = 'sims/temp' #in case saving stuff\n",
    "\n",
    "ex = Experiment(name='testing', ingredients=[dataset, model, training], interactive=True)\n",
    "ex.add_config(no_cuda=False, save_folder=temp_path,\n",
    "              experiment_name='multi-task')\n",
    "\n",
    "ex.add_package_dependency('torch', torch.__version__)\n",
    "if OBSERVE:\n",
    "    ex.observers.append(FileStorageObserver.create('sims'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e63aa4",
   "metadata": {},
   "source": [
    "Helper function for setting seed/device.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f44f6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "@ex.capture\n",
    "def set_seed_and_device(seed, no_cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available() and not no_cuda:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    return device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e19422",
   "metadata": {},
   "source": [
    "## Define main method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c704cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ex.main\n",
    "def main(_config, seed):\n",
    "    global task1_mse_pre\n",
    "    global task2_mse\n",
    "    global task1_mse_post\n",
    "    \n",
    "    global pred_task1_baseline\n",
    "    global pred_task2\n",
    "    global pred_task1_switch\n",
    "    \n",
    "    global targets_task1\n",
    "    global targets_task2\n",
    "    global targets_task1\n",
    "    \n",
    "    , , \n",
    "    \n",
    "    , , \n",
    "    \n",
    "    no_cuda = _config['no_cuda']\n",
    "    print(\"config:\", _config)\n",
    "    \n",
    "    assert _config['model']['apply_cerebellum'] == True, 'This task requires the cerebellum!'\n",
    "    epochs = _config['training']['epochs']\n",
    "        \n",
    "    input_size = _config['dataset']['input_D']\n",
    "    output_size = 2\n",
    "    seq_len =  _config['dataset']['seq_len']\n",
    "    classification = False      \n",
    "    predict_last = False     \n",
    "    \n",
    "    log_interval = 5\n",
    "    batch_size = _config['training']['batch_size']\n",
    "\n",
    "    # Init metrics\n",
    "    loss, metrics = init_metrics('mse', ['mse'])\n",
    "\n",
    "    device = set_seed_and_device(seed, no_cuda)\n",
    "    \n",
    "    training_set, validation_set, test_set = load_dataset(batch_size=batch_size)\n",
    "    print(\"retrieved dataset\")  \n",
    "    model = init_model(input_size=input_size, output_size=output_size)\n",
    "    print(\"initialised model\")    \n",
    "\n",
    "    model.init_dataset_details(batch_size, seq_len, classification,\n",
    "                                 predict_last)    \n",
    "        \n",
    "    model = model.to(device=device)\n",
    "    model.set_2task_model() #multi-task learning\n",
    "    \n",
    "    optimizer = init_optimizer(model=model) \n",
    "    \n",
    "    # Init engines\n",
    "    trainer = create_rnn_trainer(model, optimizer, loss, device=device)\n",
    "    validator = create_rnn_evaluator(model, metrics, device=device)\n",
    "\n",
    "    @trainer.on(Events.EPOCH_STARTED)\n",
    "    def print_epoch(engine):\n",
    "        nepoch = engine.state.epoch\n",
    "        if nepoch % log_interval == 0:\n",
    "            print('#'*75)\n",
    "            print(\"Epoch: {}\".format(engine.state.epoch))   \n",
    "            print('#'*75)\n",
    "        \n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def validate(engine):\n",
    "        validator.run(validation_set)\n",
    "    \n",
    "    # Exception for early termination\n",
    "    @trainer.on(Events.EXCEPTION_RAISED)\n",
    "    def terminate(engine, exception):\n",
    "        if isinstance(exception, KeyboardInterrupt):\n",
    "            engine.should_terminate=True\n",
    "\n",
    "    # Record training progression\n",
    "    global tracer\n",
    "    tracer = Tracer(metrics).attach(trainer)\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_training(engine):        \n",
    "        loss_epoch = tracer.loss[-1]\n",
    "        ex.log_scalar('training_loss', loss_epoch)\n",
    "        tracer.loss.clear()\n",
    "        \n",
    "        if model.apply_cerebellum and model.cerebellum.record_losses:\n",
    "            for IO_type, error_list in model.cerebellum.recorded_losses.items():\n",
    "                name = 'cerebellar_{}_loss'.format(IO_type)\n",
    "                loss_epoch = np.nanmean(error_list)\n",
    "                ex.log_scalar(name, loss_epoch)\n",
    "                \n",
    "                error_list.clear()\n",
    "                    \n",
    "    val_metrics = {}\n",
    "    for key in metrics.keys():\n",
    "        val_metrics[key] = []\n",
    "\n",
    "    @validator.on(Events.EPOCH_COMPLETED)\n",
    "    def log_validation(engine):\n",
    "        for metric, value in engine.state.metrics.items():\n",
    "            if 'mse' in metric: #correct for difference between torch.lossMSE and ignite.lossMSE\n",
    "                if not model.predict_last:\n",
    "                    value = value/seq_len \n",
    "                if metric == 'mse':\n",
    "                    value = value/output_size\n",
    "            \n",
    "            print(\"Val loss:\", value)\n",
    "            ex.log_scalar('val_{}'.format(metric), value)\n",
    "            val_metrics[metric].append(value)\n",
    "\n",
    "    # Attach model checkpoint\n",
    "    def score_fn(engine):\n",
    "        return -engine.state.metrics[list(metrics)[0]]\n",
    "\n",
    "    global checkpoint\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        dirname=_config['save_folder'],\n",
    "        filename_prefix='disent',\n",
    "        score_function=score_fn,\n",
    "        create_dir=True,\n",
    "        require_empty=False,\n",
    "        save_as_state_dict=True\n",
    "    )\n",
    "    \n",
    "    validator.add_event_handler(Events.COMPLETED, checkpoint, {'model': model})\n",
    "    \n",
    "    print(\"epochs is\", epochs)\n",
    "    \n",
    "    print(\"starting training for task 1\")\n",
    "    trainer.run(training_set, max_epochs=epochs)\n",
    "    print(\"finished training for task 1\")\n",
    "            \n",
    "    #save final model (not necessarily best)\n",
    "    final_model_path = temp_path + 'final-model.pt'\n",
    "    torch.save(model.state_dict(), final_model_path)\n",
    "    ex.add_artifact(final_model_path, 'final-model.pt')\n",
    "    os.remove(final_model_path)\n",
    "        \n",
    "    # Run on test data\n",
    "    model.eval()\n",
    "    model.load_state_dict(checkpoint.best_model)\n",
    "    tester = create_rnn_evaluator(model, metrics, device=device,)\n",
    "\n",
    "    test_metrics = tester.run(test_set).metrics\n",
    "    \n",
    "    # Save best model performance and state\n",
    "    for metric, value in test_metrics.items():\n",
    "        print(\"Test {}: {}\".format(metric, value))\n",
    "        ex.log_scalar('test_{}'.format(metric), value)\n",
    "    #ex.add_artifact(checkpoint.last_checkpoint, 'trained-model')\n",
    "    ex.add_artifact(checkpoint.last_checkpoint, 'best-model.pt')\n",
    "    \n",
    "    os.remove(checkpoint.last_checkpoint)   \n",
    "    \n",
    "    model.eval()\n",
    "    task1_mse_pre = tester.run(test_set).metrics['mse']\n",
    "    data_task1, targets_task1 = next(iter(test_set))\n",
    "    pred_task1_baseline, _ = model(data_task1)\n",
    "        \n",
    "    #consider new task with distinct cerebellar weights \n",
    "    pf_overlap = None #ratio of same PFs to use across tasks (None is zero)\n",
    "        \n",
    "    print(\"cereb parms at end of baseline:\", model.cerebellum.input_trigger.weight[0,:5])\n",
    "    model.set_task_number(1, pf_overlap=pf_overlap) \n",
    "    \n",
    "    trainer.remove_event_handler(validate, Events.EPOCH_COMPLETED)\n",
    "    \n",
    "    # need to make sure the optimiser is updating the correct cerebellar weights\n",
    "    del optimizer.param_groups[2]\n",
    "    optimizer.add_param_group(\n",
    "        {'params' : model.cerebellum.parameters()}\n",
    "        )     \n",
    "    \n",
    "    training_set2, validation_set2, test_set2 = load_dataset(arc=1, \n",
    "                                                            batch_size=batch_size,)\n",
    "    \n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def validate(engine):\n",
    "        validator.run(validation_set2)\n",
    "    \n",
    "    \n",
    "    trainer.state.max_epochs = None\n",
    "    nepochs_task2 = 10\n",
    "    print(\"starting training for task 2\")\n",
    "    trainer.run(training_set2, max_epochs=nepochs_task2)\n",
    "    print(\"finished training for task 2\")\n",
    "            \n",
    "    model.eval()\n",
    "    task2_mse = tester.run(test_set2).metrics ['mse']   \n",
    "    data_task2, targets_task2 = next(iter(test_set2))\n",
    "    pred_task2, _ = model(data_task2)    \n",
    "    \n",
    "    model.set_task_number(0)\n",
    "    \n",
    "    task1_mse_post = tester.run(test_set).metrics['mse']\n",
    "    pred_task1_switch, _ = model(data_task1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a98c7cb",
   "metadata": {},
   "source": [
    "## Run experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17f2084d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - testing - No observers have been added to this run\n",
      "INFO - testing - Running command 'main'\n",
      "INFO - testing - Started\n",
      "/home/joe/Documents/other/workshops/mainz_2023/labs/ccLoops-main/src/dataset/linedraw.py:80: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  alpha = np.arctan(opp/adj) #sohcahtoa!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: {'no_cuda': False, 'save_folder': 'sims/temp', 'experiment_name': 'multi-task', 'seed': 123, 'dataset': {'seq_len': 20, 'training_size': 1000, 'test_size': 1000, 'train_val_split': 0.2, 'fixdata': False, 'train_noise_var': 0.1, 'test_noise_var': 0.1, 'input_D': 10, 'npoints': 6, 'mag': 1, 'arc': 0, 'equal_spacing': False}, 'model': {'rnn_type': 'RNN_eprop', 'n_layers': 1, 'hidden_size': 50, 'input_size': 2, 'output_size': 1, 'evec_scale': None, 'readout_from_cereb': False, 'apply_cerebellum': True, 'bias': False, 'fixed_rnn': True, 'alpha': 0.5, 'cereb_params': {'pons_sizes': {'PFC_pons_size': None, 'MC_pons_size': 0, 'targ_pons_size': 0, 'inp_pons_size': 0}, 'IO_sizes': {'PFC_IO_size': 0, 'MC_IO_size': 0, 'targ_IO_size': None, 'inp_IO_size': 0}, 'IO_delays': {'PFC_IO_delay': 5, 'MC_IO_delay': 3, 'targ_IO_delay': 3, 'inp_IO_delay': 2}, 'hidden_size': 1000, 'num_hidden_layers': 1, 'nfibres': None, 'zero_output': False, 'bias': False, 'do_final_learning': True, 'temp_basis': False}}, 'training': {'epochs': 5, 'batch_size': 10, 'optimizer': 'adam', 'lr_rnn': 0.001, 'lr_readout': 0.001, 'lr_cerebellum': 0.001, 'l2_norm': 0.0, 'rate_reg': 0.0, 'clip': 1.0, 'keep_hidden': False}}\n",
      "retrieved dataset\n",
      "initialised model\n",
      "epochs is 5\n",
      "starting training for task 1\n",
      "Val loss: 0.08410492706298828\n",
      "Val loss: 0.036501396179199216\n",
      "Val loss: 0.02295967674255371\n",
      "Val loss: 0.013718506813049317\n",
      "###########################################################################\n",
      "Epoch: 5\n",
      "###########################################################################\n",
      "Val loss: 0.010235389709472655\n",
      "finished training for task 1\n",
      "Test mse: 0.3996089782714844\n",
      "cereb parms at end of baseline: tensor([-0.1115,  0.1313, -0.0847,  0.1222, -0.1044], grad_fn=<SliceBackward0>)\n",
      "starting training for task 2\n",
      "Val loss: 0.044638763427734374\n",
      "Val loss: 0.029738502502441404\n",
      "Val loss: 0.036417472839355466\n",
      "Val loss: 0.052648349761962886\n",
      "###########################################################################\n",
      "Epoch: 5\n",
      "###########################################################################\n",
      "Val loss: 0.023037076950073242\n",
      "Val loss: 0.018740612030029295\n",
      "Val loss: 0.018386034011840822\n",
      "Val loss: 0.012626623153686522\n",
      "Val loss: 0.01534392261505127\n",
      "###########################################################################\n",
      "Epoch: 10\n",
      "###########################################################################\n",
      "Val loss: 0.014253713607788085\n",
      "finished training for task 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - testing - Completed after 0:00:32\n"
     ]
    }
   ],
   "source": [
    "  r = ex.run(config_updates={'training': {'epochs': 5},\n",
    "               'model': {'apply_cerebellum': True,},\n",
    "               'seed': 123})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d427357",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_task1_baseline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror (MSE)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(\u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m---> 10\u001b[0m preds_all \u001b[38;5;241m=\u001b[39m [\u001b[43mpred_task1_baseline\u001b[49m, pred_task2, pred_task1_switch]\n\u001b[1;32m     11\u001b[0m targets_all \u001b[38;5;241m=\u001b[39m [targets_task1, targets_task2, targets_task1]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (preds, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(preds_all, targets_all)):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_task1_baseline' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    fig = plt.figure(0)\n",
    "    x = np.arange(3)\n",
    "    errors = [task1_mse_pre, task2_mse, task1_mse_post]\n",
    "    xticklabels = ['task 1 (baseline)', 'task 2', 'task 1 (zero-shot switch)']\n",
    "    plt.bar(x, errors)\n",
    "    plt.xticks(x, labels=xticklabels)\n",
    "    plt.ylabel(\"error (MSE)\")\n",
    "    \n",
    "    fig = plt.figure(1, (6, 2))\n",
    "    preds_all = [pred_task1_baseline, pred_task2, pred_task1_switch]\n",
    "    targets_all = [targets_task1, targets_task2, targets_task1]\n",
    "    \n",
    "    for i, (preds, targets) in enumerate(zip(preds_all, targets_all)):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.axis('off')\n",
    "        plt.title(xticklabels[i])\n",
    "        \n",
    "        preds = preds.detach().numpy()\n",
    "        targets = targets.numpy()\n",
    "        unique_inds =  np.unique(targets, axis=0, return_index=True)[1]\n",
    "        \n",
    "        for ind in unique_inds:\n",
    "            plt.plot(preds[ind, :, 0], preds[ind, :, 1], color='orange')\n",
    "            plt.plot(targets[ind, :, 0], targets[ind, :, 1], color='black', linestyle='dotted')\n",
    "            \n",
    "        plt.xlim([-1,1])\n",
    "        plt.ylim([-1,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
